{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS Spam Classification using Multinomial Naive Bayes\n",
    "\n",
    "In this project, we will create three models based on Multinomial NB which differs on the basis of features. \n",
    "\n",
    "First model will classify using the standard formula for Multinomial Naive Bayes.\n",
    "\n",
    "The second model will take in account the length of documents as feature, since length have a visible effect on class (Spam or Ham) as shown in the graph you will see shortly.\n",
    "\n",
    "```\n",
    "P(cl|doc,len) = (P(doc,len|cl) * P(cl)) / P(doc,len)\n",
    "              = (P(doc|cl) * P(len|cl) * P(cl)) / (P(doc) * P(len))\n",
    "              = (P(doc|cl) * P(cl)) / P(doc) * P(len|cl) / P(len)\n",
    "              = P(cl|doc) * P(len|cl) / P(len)\n",
    "```\n",
    "              \n",
    "\n",
    "\n",
    "The third model will take in account the length as well as the term frequency as features for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Necessary Modules\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data\n",
    "\n",
    "We will read the raw text file and store the data in an organized way into a csv. We will create a column SPAM. Inside the SPAM column, 1 denotes that the document is spam, 0 denotes it is not spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  Rows Written\n",
      "1000  Rows Written\n",
      "1500  Rows Written\n",
      "2000  Rows Written\n",
      "2500  Rows Written\n",
      "3000  Rows Written\n",
      "3500  Rows Written\n",
      "4000  Rows Written\n",
      "4500  Rows Written\n",
      "5000  Rows Written\n",
      "5500  Rows Written\n",
      "Total Spam SMS:  747\n",
      "Total Ham SMS:  4827\n"
     ]
    }
   ],
   "source": [
    "data_file = 'SMSSpamCollection.txt'\n",
    "\n",
    "with open(data_file,'r') as f:\n",
    "    csv_file = open(\"data.csv\", \"w+\") \n",
    "    columnTitleRow = \"SMS,SPAM\\n\"\n",
    "    csv_file.write(columnTitleRow)\n",
    "    counter = 0\n",
    "    spamCounter = 0\n",
    "    hamCounter = 0\n",
    "    for line in f:\n",
    "        counter+=1\n",
    "        if counter%500==0:\n",
    "            print(counter,\" Rows Written\")\n",
    "        if 'spam' in line[:4]:\n",
    "            line = line[4:]\n",
    "            t=1\n",
    "            spamCounter+=1\n",
    "        else:\n",
    "            line = line[3:]\n",
    "            t=0\n",
    "            hamCounter+=1\n",
    "        row = line.replace(\"\\n\",\"\").replace(\",\",\"\").replace(\"\\t\",\"\") + \",\" + str(t) + \"\\n\"\n",
    "        csv_file.write(row)\n",
    "csv_file.close()\n",
    "\n",
    "print(\"Total Spam SMS: \",spamCounter)\n",
    "print(\"Total Ham SMS: \",hamCounter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset \n",
    "\n",
    "Now let's load data into dataframe from the csv we created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 SMS  SPAM\n",
      "0  Go until jurong point crazy.. Available only i...     0\n",
      "1                      Ok lar... Joking wif u oni...     0\n",
      "2  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
      "3  U dun say so early hor... U c already then say...     0\n",
      "4  Nah I don't think he goes to usf he lives arou...     0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting New Feature\n",
    "\n",
    "Creating a new feature LENGTH, which will be used as a feature to demonstrate the improvement in accuracy. It can be clearly seen in scatterplot that for spam sms, the length is not more than 200. For Hams, the legth goes upto 910."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 SMS  SPAM  LENGTH\n",
      "0  Go until jurong point crazy.. Available only i...     0     110\n",
      "1                      Ok lar... Joking wif u oni...     0      29\n",
      "2  Free entry in 2 a wkly comp to win FA Cup fina...     1     155\n",
      "3  U dun say so early hor... U c already then say...     0      49\n",
      "4  Nah I don't think he goes to usf he lives arou...     0      60\n",
      "\n",
      "\n",
      "Max length of HAM:  910\n",
      "Max length of SPAM:  222\n"
     ]
    }
   ],
   "source": [
    "df['LENGTH'] = df['SMS'].apply(len)\n",
    "print(df.head())\n",
    "print(\"\\n\")\n",
    "print(\"Max length of HAM: \",df[(df['SPAM']==0)].LENGTH.max())\n",
    "print(\"Max length of SPAM: \",df[(df['SPAM']==1)].LENGTH.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVwAAAFcCAYAAACEFgYsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA1/ICySJta+hAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25dfb5029b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot( x=\"SPAM\", y=\"LENGTH\", data=df, fit_reg=False, hue='SPAM', legend=False)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Punctuations and changing to lower case\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['SMS'] = df['SMS'].str.lower()\n",
    "df['SMS'] = df['SMS'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our classifier\n",
    "\n",
    "Following is our custom NB classifier class that will provide some usefull apis too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # All variables used in calculations are kept private\n",
    "        self.__TOTAL_SPAM = 0\n",
    "        self.__TOTAL_HAM = 0\n",
    "        self.__PRIOR_SPAM = 0\n",
    "        self.__PRIOR_HAM = 0\n",
    "        self.__TERMS_IN_SPAM = 0\n",
    "        self.__TERMS_IN_HAM = 0\n",
    "        self.__TOTAL_TERMS_IN_SPAM = 0\n",
    "        self.__TOTAL_TERMS_IN_HAM = 0\n",
    "        self.__AVG_LENGTH_SPAM = 0\n",
    "        self.__AVG_LENGTH_HAM = 0\n",
    "        self.__V = 0\n",
    "        self.__SPAM_VOCAB = 0\n",
    "        self.__HAM_VOCAB = 0\n",
    "        self.mode = 0\n",
    "\n",
    "    # Api to split data in training and validation datasets\n",
    "    def split_data(self,df,ratio):\n",
    "        df_size = len(df.index)\n",
    "        return df.iloc[int(df_size * ratio):] , df.iloc[:int(df_size * ratio)]\n",
    "    \n",
    "    # Method to train our classifier\n",
    "    # Mode == 0 => Standard NB\n",
    "    # Mode == 1 => Standard NB + Length as Feature\n",
    "    # Mode == 2 => Standard NB + Length and Term Frequency as Features\n",
    "    def fit(self, df, mode):\n",
    "        self.mode = mode\n",
    "        data_info = training_df.groupby('SPAM').size()\n",
    "\n",
    "        self.__TOTAL_SPAM = data_info[1]\n",
    "        self.__TOTAL_HAM = data_info[0]\n",
    "        self.__PRIOR_SPAM = self.__TOTAL_SPAM/(self.__TOTAL_SPAM + self.__TOTAL_HAM)\n",
    "        self.__PRIOR_HAM = self.__TOTAL_HAM/(self.__TOTAL_SPAM + self.__TOTAL_HAM)\n",
    "\n",
    "        spam_df = df[df['SPAM']==1]\n",
    "        ham_df = df[df['SPAM']==0]\n",
    "\n",
    "        if mode == 1:\n",
    "            self.__AVG_LENGTH_SPAM = spam_df['LENGTH'].mean()\n",
    "            self.__AVG_LENGTH_HAM = ham_df['LENGTH'].mean()\n",
    "\n",
    "\n",
    "        self.__SPAM_VOCAB = collections.Counter([y for x in spam_df['SMS'].tolist() for y in x.split(\" \") ])\n",
    "        self.__HAM_VOCAB = collections.Counter([y for x in ham_df['SMS'].tolist() for y in x.split(\" \") ]) \n",
    "\n",
    "        self.__TERMS_IN_SPAM = len(self.__SPAM_VOCAB)\n",
    "        self.__TERMS_IN_HAM = len(self.__HAM_VOCAB)\n",
    "        self.__TOTAL_TERMS_IN_SPAM = len(spam_df.index)\n",
    "        self.__TOTAL_TERMS_IN_HAM = len(ham_df.index)\n",
    "\n",
    "        self.__V = self.__TERMS_IN_SPAM + self.__TERMS_IN_HAM\n",
    "            \n",
    "        \n",
    "        \n",
    "   # Method to predict any single SMS     \n",
    "    def predict(self,sms):\n",
    "        sms = sms.lower()\n",
    "        sms = [''.join(c for c in s if c not in string.punctuation) for s in sms]\n",
    "        sms = ''.join(sms).split(\" \")\n",
    "        spam_prob = self.__PRIOR_SPAM\n",
    "        ham_prob = self.__PRIOR_HAM\n",
    "\n",
    "        most_common_spam = self.__SPAM_VOCAB.most_common(1)[0][1]\n",
    "        most_common_ham = self.__HAM_VOCAB.most_common(1)[0][1]\n",
    "        \n",
    "        for term in sms:\n",
    "            if self.mode == 1:\n",
    "                spam_prob = spam_prob * ( (self.__SPAM_VOCAB[term] + 1) / (self.__TERMS_IN_SPAM + self.__V) ) * ( (self.__AVG_LENGTH_SPAM + 1) / (len(sms) + 1) )\n",
    "                ham_prob = ham_prob * ( (self.__HAM_VOCAB[term] + 1) / (self.__TERMS_IN_HAM + self.__V) ) * ( (self.__AVG_LENGTH_HAM + 1) / (len(sms) + 1) )\n",
    "\n",
    "            if self.mode == 2:\n",
    "                spam_prob = spam_prob * ( (self.__SPAM_VOCAB[term] + 1) / (self.__TERMS_IN_SPAM + self.__V) ) * ( (self.__AVG_LENGTH_SPAM + 1) / (len(sms) + 1) ) * ( (self.__SPAM_VOCAB[term] + 1) / most_common_spam )    \n",
    "                ham_prob = ham_prob * ( (self.__HAM_VOCAB[term] + 1) / (self.__TERMS_IN_HAM + self.__V) ) * ( (self.__AVG_LENGTH_HAM + 1) / (len(sms) + 1) )  * ( (self.__HAM_VOCAB[term] + 1) / most_common_ham)\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                spam_prob = spam_prob * ( (self.__SPAM_VOCAB[term] + 1) / (self.__TERMS_IN_SPAM + self.__V) )\n",
    "                ham_prob = ham_prob * ( (self.__HAM_VOCAB[term] + 1) / (self.__TERMS_IN_HAM + self.__V) )  \n",
    "\n",
    "            \n",
    "        if spam_prob>ham_prob:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    \n",
    "    # Method to perform validation in batch\n",
    "    def validate(self,df):\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        correct_spam = 0\n",
    "        correct_ham = 0\n",
    "        for index, row in df.iterrows():\n",
    "            if self.predict(row['SMS'])==row['SPAM']:\n",
    "                correct+=1\n",
    "                if row['SPAM'] == 1:\n",
    "                    correct_spam = correct_spam+1\n",
    "                else:\n",
    "                    correct_ham = correct_ham+1\n",
    "\n",
    "            total+=1\n",
    "            if(total%50==0):\n",
    "                print(\"Querries Processed: \",total)\n",
    "\n",
    "        print(\"Accuracy: \",round((correct/total)*100, 2),\"%\")\n",
    "        print(\"Correct Predictions: \",correct,\"/\",len(df.index))\n",
    "\n",
    "        data_info = df.groupby('SPAM').size()\n",
    "        TOTAL_SPAM = data_info[1]\n",
    "        TOTAL_HAM = data_info[0]    \n",
    "\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(\"[\",correct_spam,TOTAL_SPAM,\"]\\n[\",correct_ham,TOTAL_HAM,\"]\")\n",
    "\n",
    "    \n",
    "    \n",
    "    def most_common_spam(self,num):\n",
    "        try:\n",
    "            print(\"\\n======= Most Common Spam Terms & their Frequency=======\\n\\n\")\n",
    "            for term, freq in self.__SPAM_VOCAB.most_common(num):\n",
    "                print(term, freq)\n",
    "            \n",
    "        except:\n",
    "            print(\"Vocab Empty!\")\n",
    "        \n",
    "    def most_common_ham(self,num):\n",
    "        try:\n",
    "            print(\"\\n======= Most Common Ham Terms & their Frequency=======\\n\\n\")\n",
    "            for term, freq in self.__HAM_VOCAB.most_common(num):\n",
    "                print(term, freq)        \n",
    "        except:\n",
    "            print(\"Vocab Empty!\")\n",
    "            \n",
    "    def save_model(self):\n",
    "        with open(\"model.txt\",\"w+\") as f:\n",
    "            f.write(str(self.__TOTAL_SPAM))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(str(self.__TOTAL_HAM))\n",
    "            f.write(\"\\n\")            \n",
    "            f.write(str(self.__PRIOR_SPAM))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(str(self.__PRIOR_HAM))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(str(self.__TERMS_IN_SPAM))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(str(self.__TERMS_IN_HAM))\n",
    "            f.write(\"\\n\")            \n",
    "            f.write(str(self.__TOTAL_TERMS_IN_SPAM))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(str(self.__TOTAL_TERMS_IN_HAM))\n",
    "            f.write(\"\\n\")    \n",
    "            f.write(str(self.__AVG_LENGTH_SPAM))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(str(self.__AVG_LENGTH_HAM))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(str(self.__V))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(str(self.__SPAM_VOCAB))\n",
    "            f.write(\"\\n\")            \n",
    "            f.write(str(self.__HAM_VOCAB))\n",
    "        print(\"Model Saved!\")\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Lets test our classifier. First split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes()\n",
    "# 10% for validation, 90% for training\n",
    "validation_data, training_data = nb.split_data(df,0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with standard Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querries Processed:  50\n",
      "Querries Processed:  100\n",
      "Querries Processed:  150\n",
      "Querries Processed:  200\n",
      "Querries Processed:  250\n",
      "Querries Processed:  300\n",
      "Querries Processed:  350\n",
      "Querries Processed:  400\n",
      "Querries Processed:  450\n",
      "Querries Processed:  500\n",
      "Querries Processed:  550\n",
      "Accuracy:  96.42 %\n",
      "Correct Predictions:  538 / 558\n",
      "Confusion Matrix\n",
      "[ 52 72 ]\n",
      "[ 486 486 ]\n"
     ]
    }
   ],
   "source": [
    "# Training our classifier\n",
    "nb.fit(training_data,0)\n",
    "# Validating Our Classifier\n",
    "nb.validate(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB with LENGTH of documents as Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querries Processed:  50\n",
      "Querries Processed:  100\n",
      "Querries Processed:  150\n",
      "Querries Processed:  200\n",
      "Querries Processed:  250\n",
      "Querries Processed:  300\n",
      "Querries Processed:  350\n",
      "Querries Processed:  400\n",
      "Querries Processed:  450\n",
      "Querries Processed:  500\n",
      "Querries Processed:  550\n",
      "Accuracy:  98.39 %\n",
      "Correct Predictions:  549 / 558\n",
      "Confusion Matrix\n",
      "[ 65 72 ]\n",
      "[ 484 486 ]\n"
     ]
    }
   ],
   "source": [
    "# Training our classifier\n",
    "nb.fit(training_data,1)\n",
    "# Validating Our Classifier\n",
    "nb.validate(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB with LENGTH of documents and Term Frequencty as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querries Processed:  50\n",
      "Querries Processed:  100\n",
      "Querries Processed:  150\n",
      "Querries Processed:  200\n",
      "Querries Processed:  250\n",
      "Querries Processed:  300\n",
      "Querries Processed:  350\n",
      "Querries Processed:  400\n",
      "Querries Processed:  450\n",
      "Querries Processed:  500\n",
      "Querries Processed:  550\n",
      "Accuracy:  98.21 %\n",
      "Correct Predictions:  548 / 558\n",
      "Confusion Matrix\n",
      "[ 70 72 ]\n",
      "[ 478 486 ]\n"
     ]
    }
   ],
   "source": [
    "# Training our classifier\n",
    "nb.fit(training_data,2)\n",
    "# Validating Our Classifier\n",
    "nb.validate(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common N terms in spams and hams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Most Common Spam Terms & their Frequency=======\n",
      "\n",
      "\n",
      "to 624\n",
      "a 343\n",
      "call 304\n",
      "you 258\n",
      "your 234\n",
      " 227\n",
      "free 190\n",
      "the 182\n",
      "now 176\n",
      "for 176\n",
      "\n",
      "======= Most Common Ham Terms & their Frequency=======\n",
      "\n",
      "\n",
      "i 1963\n",
      "you 1656\n",
      " 1435\n",
      "to 1423\n",
      "the 1022\n",
      "a 960\n",
      "u 888\n",
      "and 776\n",
      "in 733\n",
      "me 687\n"
     ]
    }
   ],
   "source": [
    "nb.most_common_spam(10)\n",
    "nb.most_common_ham(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "It is clear from the results that the accuracy is increase around 2% as we introduced two new features in the multinomial naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
